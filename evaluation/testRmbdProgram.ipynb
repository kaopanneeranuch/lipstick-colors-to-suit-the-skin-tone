{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- encoding: utf-8 -*-\n",
    "\n",
    "from models.model import BiSeNet\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "import attr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the HSV color space to the RGB color space\n",
    "def hsv2rgb(h, s, v):\n",
    "    h = float(h)\n",
    "    s = float(s)\n",
    "    v = float(v)\n",
    "    h60 = h / 60.0\n",
    "    h60f = math.floor(h60)\n",
    "    hi = int(h60f) % 6\n",
    "    f = h60 - h60f\n",
    "    p = v * (1 - s)\n",
    "    q = v * (1 - f * s)\n",
    "    t = v * (1 - (1 - f) * s)\n",
    "    r, g, b = 0, 0, 0\n",
    "    if hi == 0: r, g, b = v, t, p\n",
    "    elif hi == 1: r, g, b = q, v, p\n",
    "    elif hi == 2: r, g, b = p, v, t\n",
    "    elif hi == 3: r, g, b = p, q, v\n",
    "    elif hi == 4: r, g, b = t, p, v\n",
    "    elif hi == 5: r, g, b = v, p, q\n",
    "    r, g, b = int(r * 255), int(g * 255), int(b * 255)\n",
    "    return r, g, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RGB color space to the HSV color space\n",
    "def rgb2hsv(r, g, b):\n",
    "    r, g, b = r/255.0, g/255.0, b/255.0\n",
    "    mx = max(r, g, b)\n",
    "    mn = min(r, g, b)\n",
    "    m = mx-mn\n",
    "    if mx == mn:\n",
    "        h = 0\n",
    "    elif mx == r:\n",
    "        if g >= b:\n",
    "            h = ((g-b)/m)*60\n",
    "        else:\n",
    "            h = ((g-b)/m)*60 + 360\n",
    "    elif mx == g:\n",
    "        h = ((b-r)/m)*60 + 120\n",
    "    elif mx == b:\n",
    "        h = ((r-g)/m)*60 + 240\n",
    "    if mx == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = m/mx\n",
    "    v = mx\n",
    "    # h:0-360, s:0-1, v:0-1\n",
    "    # H:0-180, S:0-255, V:0-255\n",
    "    H = h / 2\n",
    "    S = s * 255.0\n",
    "    V = v * 255.0\n",
    "    return H, S, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RGB color space to the HEX color space\n",
    "def rgb2hex(r, g, b):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(r, g, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color distance between two RGB colors\n",
    "def ColourDistance(rgb_1, rgb_2):\n",
    "    R_1, G_1, B_1 = rgb_1\n",
    "    R_2, G_2, B_2 = rgb_2\n",
    "    rmean = (R_1 + R_2) / 2\n",
    "    R = R_1 - R_2\n",
    "    G = G_1 - G_2\n",
    "    B = B_1 - B_2\n",
    "    return math.sqrt((2 + rmean / 256) * (R ** 2) + 4 * (G ** 2) + (2 + (255 - rmean) / 256) * (B ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMBD\n",
    "def rmDarkBright(imgArray, parsing):\n",
    "    for i in range(512):\n",
    "        for j in range(512):\n",
    "            rgb = imgArray[i][j]\n",
    "            r = rgb[0]\n",
    "            g = rgb[1]\n",
    "            b = rgb[2]\n",
    "            h, s, v = rgb2hsv(r, g, b)\n",
    "            if (parsing[i][j] == 12 or parsing[i][j] == 13 or parsing[i][j] == 10) and (v < 5 or v > 250):\n",
    "                parsing[i][j] = 1\n",
    "    return parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ret_dic\n",
    "with open('./json/lipsticksMod.json', 'r', encoding='utf-8') as f:\n",
    "# with open('data.json', 'r', encoding='utf-8') as f:\n",
    "    ret_dic = json.load(f)\n",
    "    sum = len(ret_dic)\n",
    "    RGB_array = np.zeros((sum, 3), dtype=int)\n",
    "    for i in range(sum):\n",
    "        color_value = ret_dic[i]['color']\n",
    "        ret_dic[i]['distance'] = 999\n",
    "        ret_dic[i]['rgb'] = [0, 0, 0]\n",
    "        ret_dic[i]['rgb'][0] = int(color_value[1:3], 16)\n",
    "        ret_dic[i]['rgb'][1] = int(color_value[3:5], 16)\n",
    "        ret_dic[i]['rgb'][2] = int(color_value[5:7], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiSeNet(\n",
       "  (cp): ContextPath(\n",
       "    (resnet): Resnet18(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (arm16): AttentionRefinementModule(\n",
       "      (conv): ConvBNReLU(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sigmoid_atten): Sigmoid()\n",
       "    )\n",
       "    (arm32): AttentionRefinementModule(\n",
       "      (conv): ConvBNReLU(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_atten): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn_atten): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sigmoid_atten): Sigmoid()\n",
       "    )\n",
       "    (conv_head32): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_head16): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_avg): ConvBNReLU(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (ffm): FeatureFusionModule(\n",
       "    (convblk): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (conv_out): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_out16): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (conv_out32): BiSeNetOutput(\n",
       "    (conv): ConvBNReLU(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_out): Conv2d(64, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load into memory\n",
    "# Load model\n",
    "n_classes = 19\n",
    "net = BiSeNet(n_classes=n_classes)\n",
    "save_pth = '../res/cp/79999_iter.pth'\n",
    "net.load_state_dict(torch.load(save_pth, map_location=torch.device('cpu')))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor\n",
    "to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count correct number and fail number\n",
    "shootCount = 0\n",
    "failCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sub-dataset dir\n",
    "datasetDirPath = \"./testDataset/dataset\" # Change para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgId: face0, lip: [127, 65, 57] nose:[168, 107, 75]\n",
      "imgId: face10, lip: [193, 125, 116] nose:[220, 167, 137]\n",
      "imgId: face12, lip: [163, 105, 114] nose:[217, 189, 177]\n",
      "imgId: face13, lip: [187, 127, 109] nose:[210, 170, 139]\n",
      "imgId: face14, lip: [151, 85, 62] nose:[217, 172, 140]\n",
      "imgId: face15, lip: [129, 60, 44] nose:[216, 165, 131]\n",
      "imgId: face16, lip: [201, 104, 116] nose:[215, 152, 129]\n",
      "imgId: face17, lip: [151, 95, 76] nose:[212, 173, 146]\n",
      "imgId: face2, lip: [173, 82, 125] nose:[208, 159, 160]\n",
      "imgId: face21, lip: [217, 105, 79] nose:[231, 176, 141]\n",
      "imgId: face22, lip: [189, 102, 82] nose:[214, 142, 103]\n",
      "imgId: face23, lip: [92, 30, 41] nose:[201, 173, 149]\n",
      "imgId: face24, lip: [172, 119, 105] nose:[208, 173, 156]\n",
      "imgId: face25, lip: [90, 22, 37] nose:[201, 171, 148]\n",
      "imgId: face26, lip: [159, 122, 127] nose:[199, 177, 171]\n",
      "imgId: face27, lip: [159, 126, 130] nose:[188, 166, 160]\n",
      "imgId: face28, lip: [143, 103, 100] nose:[191, 173, 168]\n",
      "imgId: face4, lip: [85, 48, 51] nose:[202, 176, 164]\n",
      "imgId: face5, lip: [162, 87, 84] nose:[182, 141, 126]\n",
      "imgId: face7, lip: [183, 112, 136] nose:[221, 173, 165]\n",
      "imgId: face8, lip: [182, 128, 105] nose:[203, 155, 122]\n"
     ]
    }
   ],
   "source": [
    "list_lip = []\n",
    "list_nose = []\n",
    "list_id = []\n",
    "id = 0\n",
    "for img in os.listdir(datasetDirPath):\n",
    "    with torch.no_grad():\n",
    "        image = Image.open(datasetDirPath + \"/\" + img).convert('RGB')\n",
    "        imgArray = np.array(image)\n",
    "        image = to_tensor(image)\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        out = net(image)[0]\n",
    "        parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
    "        parsing = rmDarkBright(imgArray, parsing)\n",
    "        nosePos = np.where(parsing == 10)\n",
    "        upperLipPos = np.where(parsing == 12)\n",
    "        lowerLipPos = np.where(parsing == 13)\n",
    "\n",
    "        pointsCount = len(upperLipPos[0]) + len(lowerLipPos[0])\n",
    "        pointsCountUpper = len(upperLipPos[0])\n",
    "        pointsCountLower = len(lowerLipPos[0])\n",
    "        pointsCountNose = len(nosePos[0])\n",
    "        rgb = [0, 0, 0]\n",
    "        rgbn = [0, 0, 0]\n",
    "        if len(upperLipPos) > 0:\n",
    "            rgbUpper = np.sum(imgArray[upperLipPos[0], upperLipPos[1], :], axis=0)\n",
    "            rgb = np.sum([rgb, rgbUpper], axis=0)\n",
    "        if len(lowerLipPos) > 0:\n",
    "            rgbLower = np.sum(imgArray[lowerLipPos[0], lowerLipPos[1], :], axis=0)\n",
    "            rgb = np.sum([rgb, rgbLower], axis=0)\n",
    "        if len(nosePos) > 0:\n",
    "            rgbNose = np.sum(imgArray[nosePos[0], nosePos[1], :], axis=0)\n",
    "            rgbn = np.sum([rgbn, rgbNose], axis=0)\n",
    "        if pointsCount > 0:\n",
    "            res = [math.floor(i / pointsCount) for i in rgb]\n",
    "            resn = [math.floor(i / pointsCountNose) for i in rgbn]\n",
    "            front = img.split('.')[0]\n",
    "            imgId = front.split('_')[0]\n",
    "            list_lip.append(rgb2hex(res[0],res[1],res[2]))\n",
    "            list_nose.append(rgb2hex(resn[0],resn[1],resn[2]))\n",
    "            id += 1\n",
    "            list_id.append(id)\n",
    "            print('imgId: ' + imgId + ', lip: ' + str(res) + ' nose:' + str(resn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#7f4139', '#c17d74', '#a36972', '#bb7f6d', '#97553e', '#813c2c', '#c96874', '#975f4c', '#ad527d', '#d9694f', '#bd6652', '#5c1e29', '#ac7769', '#5a1625', '#9f7a7f', '#9f7e82', '#8f6764', '#553033', '#a25754', '#b77088', '#b68069']\n",
      "['#a86b4b', '#dca789', '#d9bdb1', '#d2aa8b', '#d9ac8c', '#d8a583', '#d79881', '#d4ad92', '#d09fa0', '#e7b08d', '#d68e67', '#c9ad95', '#d0ad9c', '#c9ab94', '#c7b1ab', '#bca6a0', '#bfada8', '#cab0a4', '#b68d7e', '#ddada5', '#cb9b7a']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "print(list_lip)\n",
    "print(list_nose)\n",
    "print(list_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lip': '#7f4139', 'color': '#a86b4b', 'id': 1},\n",
       " {'lip': '#c17d74', 'color': '#dca789', 'id': 2},\n",
       " {'lip': '#a36972', 'color': '#d9bdb1', 'id': 3},\n",
       " {'lip': '#bb7f6d', 'color': '#d2aa8b', 'id': 4},\n",
       " {'lip': '#97553e', 'color': '#d9ac8c', 'id': 5},\n",
       " {'lip': '#813c2c', 'color': '#d8a583', 'id': 6},\n",
       " {'lip': '#c96874', 'color': '#d79881', 'id': 7},\n",
       " {'lip': '#975f4c', 'color': '#d4ad92', 'id': 8},\n",
       " {'lip': '#ad527d', 'color': '#d09fa0', 'id': 9},\n",
       " {'lip': '#d9694f', 'color': '#e7b08d', 'id': 10},\n",
       " {'lip': '#bd6652', 'color': '#d68e67', 'id': 11},\n",
       " {'lip': '#5c1e29', 'color': '#c9ad95', 'id': 12},\n",
       " {'lip': '#ac7769', 'color': '#d0ad9c', 'id': 13},\n",
       " {'lip': '#5a1625', 'color': '#c9ab94', 'id': 14},\n",
       " {'lip': '#9f7a7f', 'color': '#c7b1ab', 'id': 15},\n",
       " {'lip': '#9f7e82', 'color': '#bca6a0', 'id': 16},\n",
       " {'lip': '#8f6764', 'color': '#bfada8', 'id': 17},\n",
       " {'lip': '#553033', 'color': '#cab0a4', 'id': 18},\n",
       " {'lip': '#a25754', 'color': '#b68d7e', 'id': 19},\n",
       " {'lip': '#b77088', 'color': '#ddada5', 'id': 20},\n",
       " {'lip': '#b68069', 'color': '#cb9b7a', 'id': 21}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listofjson = [{'lip': lip, 'color': color, 'id': id} for lip, color, id in zip(list_lip, list_nose, list_id)]\n",
    "listofjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1479x1109 at 0x189F9ED5930>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1108x1478 at 0x189F9377790>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1108x1478 at 0x189F9ED5930>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=736x984 at 0x189F9377CA0>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x750 at 0x189F9376260>\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=236x314 at 0x189F93771F0>\n"
     ]
    }
   ],
   "source": [
    "# Crop 512x512\n",
    "list_test = []\n",
    "list_title = []\n",
    "testDirPath = \"./testDataset/test/\" # Change para\n",
    "num = 1\n",
    "for img in os.listdir(testDirPath):\n",
    "    image = Image.open(testDirPath+img)\n",
    "    print(image)\n",
    "    # front = image.split('.')[0]\n",
    "    # imgId = front.split('_')[0]\n",
    "    list_test.append(image.resize((512, 512)))\n",
    "    list_title.append(num)\n",
    "    num += 1\n",
    "\n",
    "list_dict = [{'img id': title, 'img': test} for title, test in zip(list_title, list_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgId: 1, nose:[187, 143, 123], predictRes: ['#854F3C', '#C06B63', '#8C5859', '#8A5145', '#B26158']\n",
      "#bb8f7b\n",
      "imgId: 2, nose:[169, 133, 103], predictRes: ['#944E3B', '#996656', '#915240', '#8E2224', '#A25B4B']\n",
      "#a98567\n",
      "imgId: 3, nose:[180, 153, 123], predictRes: ['#854F3C', '#622F2C', '#83473A', '#601C24', '#A55354']\n",
      "#b4997b\n",
      "imgId: 4, nose:[138, 99, 71], predictRes: ['#83242C', '#562C37', '#6C3841', '#915240', '#996656']\n",
      "#8a6347\n",
      "imgId: 5, nose:[110, 86, 74], predictRes: ['#83242C', '#562C37', '#6C3841', '#7F394D', '#7A4350']\n",
      "#6e564a\n",
      "imgId: 6, nose:[220, 197, 188], predictRes: ['#955B55', '#BD8881', '#C9826C', '#B07C79', '#B18286']\n",
      "#dcc5bc\n"
     ]
    }
   ],
   "source": [
    "for dict in list_dict:\n",
    "    with torch.no_grad():\n",
    "        # image = Image.open(img).convert('RGB')\n",
    "        image = dict['img'].convert('RGB')\n",
    "        imgArray = np.array(image)\n",
    "        image = to_tensor(image)\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        out = net(image)[0]\n",
    "        parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
    "        parsing = rmDarkBright(imgArray, parsing)\n",
    "        nosePos = np.where(parsing == 10)\n",
    "\n",
    "        pointsCountNose = len(nosePos[0])\n",
    "\n",
    "        rgbn = [0, 0, 0]\n",
    "        if len(nosePos) > 0:\n",
    "            rgbNose = np.sum(imgArray[nosePos[0], nosePos[1], :], axis=0)\n",
    "            rgbn = np.sum([rgbn, rgbNose], axis=0)\n",
    "        if pointsCountNose > 0:\n",
    "            res = [math.floor(i / pointsCountNose) for i in rgbn]\n",
    "            for i in range(sum):\n",
    "                ret_dic[i]['distance'] = ColourDistance(res, ret_dic[i]['rgb'])\n",
    "            predictTmp = sorted(ret_dic, key=lambda x: float(x['distance']))[:5]\n",
    "            predictRes = []\n",
    "            for lipstick in predictTmp:\n",
    "                predictRes.append(lipstick['lip'])\n",
    "\n",
    "            imgId = dict['img id']\n",
    "            print('imgId: ' + str(imgId) + ', nose:' + str(res) + ', predictRes: ' + str(predictRes))\n",
    "\n",
    "            print(rgb2hex(res[0],res[1],res[2]))\n",
    "#             if (imgId) in predictRes:\n",
    "#                 shootCount += 1\n",
    "#             else:\n",
    "#                 failCount += 1\n",
    "# print(testDirPath + ': ' + str(shootCount) + ' success, ' + str(failCount) + ' fails, rate: ' + str(shootCount/(shootCount+failCount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgId: 1, lip: [184, 108, 109] nose:[190, 145, 124], predictRes: ['#854F3C', '#C06B63', '#B26158', '#A86863', '#A56354']\n",
      "imgId: 2, lip: [155, 107, 99] nose:[174, 139, 107], predictRes: ['#944E3B', '#6C0F19', '#8E2224', '#8F4945', '#8A5145']\n",
      "imgId: 3, lip: [142, 104, 98] nose:[172, 144, 116], predictRes: ['#622F2C', '#8F4945', '#8A5145', '#944E3B', '#6C0F19']\n",
      "imgId: 4, lip: [101, 61, 53] nose:[147, 105, 75], predictRes: ['#83242C', '#915240', '#6C3841', '#996656', '#562C37']\n",
      "imgId: 5, lip: [86, 67, 63] nose:[110, 86, 74], predictRes: ['#83242C', '#562C37', '#6C3841', '#7F394D', '#7A4350']\n",
      "imgId: 6, lip: [212, 160, 150] nose:[221, 199, 190], predictRes: ['#AC7770', '#80404B', '#B07C79', '#BD8881', '#B07F7A']\n"
     ]
    }
   ],
   "source": [
    "for img in os.listdir(testDirPath):\n",
    "    with torch.no_grad():\n",
    "        image = Image.open(testDirPath + \"/\" + img).convert('RGB')\n",
    "        imgArray = np.array(image)\n",
    "        imgArray2 = np.array(image)\n",
    "        image = to_tensor(image)\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        out = net(image)[0]\n",
    "        parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
    "        parsing = rmDarkBright(imgArray, parsing)\n",
    "        nosePos = np.where(parsing == 10)\n",
    "        upperLipPos = np.where(parsing == 12)\n",
    "        lowerLipPos = np.where(parsing == 13)\n",
    "\n",
    "        pointsCount = len(upperLipPos[0]) + len(lowerLipPos[0])\n",
    "        pointsCountUpper = len(upperLipPos[0])\n",
    "        pointsCountLower = len(lowerLipPos[0])\n",
    "        pointsCountNose = len(nosePos[0])\n",
    "        rgb = [0, 0, 0]\n",
    "        rgbn = [0, 0, 0]\n",
    "        if len(upperLipPos) > 0:\n",
    "            rgbUpper = np.sum(imgArray[upperLipPos[0], upperLipPos[1], :], axis=0)\n",
    "            rgb = np.sum([rgb, rgbUpper], axis=0)\n",
    "        if len(lowerLipPos) > 0:\n",
    "            rgbLower = np.sum(imgArray[lowerLipPos[0], lowerLipPos[1], :], axis=0)\n",
    "            rgb = np.sum([rgb, rgbLower], axis=0)\n",
    "        if len(nosePos) > 0:\n",
    "            rgbNose = np.sum(imgArray2[nosePos[0], nosePos[1], :], axis=0)\n",
    "            rgbn = np.sum([rgbn, rgbNose], axis=0)\n",
    "        if pointsCount > 0:\n",
    "            res = [math.floor(i / pointsCount) for i in rgb]\n",
    "            ress = [math.floor(i / pointsCountNose) for i in rgbn]\n",
    "            for i in range(sum):\n",
    "                ret_dic[i]['distance'] = ColourDistance(ress, ret_dic[i]['rgb'])\n",
    "            predictTmp = sorted(ret_dic, key=lambda x: float(x['distance']))[:5]\n",
    "            predictRes = []\n",
    "            for lipstick in predictTmp:\n",
    "                predictRes.append(lipstick['lip'])\n",
    "            front = img.split('.')[0]\n",
    "            imgId = front.split('_')[0]\n",
    "            print('imgId: ' + imgId + ', lip: ' + str(res) + ' nose:' + str(ress) + ', predictRes: ' + str(predictRes))\n",
    "            if (imgId) in predictRes:\n",
    "                shootCount += 1\n",
    "            else:\n",
    "                failCount += 1\n",
    "# print(testDirPath + ': ' + str(shootCount) + ' success, ' + str(failCount) + ' fails, rate: ' + str(shootCount/(shootCount+failCount)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
